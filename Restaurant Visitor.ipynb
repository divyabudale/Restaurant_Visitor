{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import seaborn as sns\n",
    "import time\n",
    "from sklearn import preprocessing\n",
    "from xgboost.sklearn import XGBClassifier, XGBRegressor\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "air_reserve = pd.read_csv(\"C:/Users/divya/Downloads/recruit-restaurant-visitor-forecasting/air_reserve/air_reserve.csv\")\n",
    "hpg_reserve = pd.read_csv(\"C:/Users/divya/Downloads/recruit-restaurant-visitor-forecasting/hpg_reserve/hpg_reserve.csv\")\n",
    "\n",
    "air_store_info = pd.read_csv(\"C:/Users/divya/Downloads/recruit-restaurant-visitor-forecasting/air_store_info/air_store_info.csv\")\n",
    "store_station = pd.read_csv(\"C:/Users/divya/Downloads/rrv_weather_data/air_store_info_with_nearest_active_station.csv\")\n",
    "hpg_store_info = pd.read_csv(\"C:/Users/divya/Downloads/recruit-restaurant-visitor-forecasting/hpg_store_info/hpg_store_info.csv\")\n",
    "\n",
    "store_id_relation = pd.read_csv(\"C:/Users/divya/Downloads/recruit-restaurant-visitor-forecasting/store_id_relation/store_id_relation.csv\")\n",
    "\n",
    "air_visit_data = pd.read_csv(\"C:/Users/divya/Downloads/recruit-restaurant-visitor-forecasting/air_visit_data/air_visit_data.csv\")\n",
    "sub = pd.read_csv(\"C:/Users/divya/Downloads/recruit-restaurant-visitor-forecasting/sample_submission/sample_submission.csv\")\n",
    "\n",
    "date_info = pd.read_csv(\"C:/Users/divya/Downloads/recruit-restaurant-visitor-forecasting/date_info/date_info.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = sub.copy()\n",
    "test['visit_date']=test['id'].str[-10:]\n",
    "test['air_store_id']=test['id'].str[:-11]\n",
    "test = test[['air_store_id','visit_date','visitors']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(284127, 3)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_data = pd.concat([air_visit_data,test])\n",
    "all_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data['visitors'] = np.log1p(all_data['visitors'])\n",
    "air_reserve['reserve_visitors'] = np.log1p(air_reserve['reserve_visitors'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform(df):\n",
    "    df['Day'] = (df['visit_date'].dt.day)\n",
    "    df['Dayofweek'] = (df['visit_date'].dt.weekday)\n",
    "    df['Month'] = (df['visit_date'].dt.month)\n",
    "    df['Year'] = (df['visit_date'].dt.year)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data['visit_date']=pd.to_datetime(all_data['visit_date'])\n",
    "all_data = transform(all_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create date columns\n",
    "le = preprocessing.LabelEncoder()\n",
    "all_data['Day_num'] = le.fit_transform(all_data.visit_date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>air_store_id</th>\n",
       "      <th>visit_date</th>\n",
       "      <th>visitors</th>\n",
       "      <th>Day</th>\n",
       "      <th>Dayofweek</th>\n",
       "      <th>Month</th>\n",
       "      <th>Year</th>\n",
       "      <th>Day_num</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>air_ba937bf13d40fb24</td>\n",
       "      <td>2016-01-13</td>\n",
       "      <td>3.258097</td>\n",
       "      <td>13</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2016</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>air_ba937bf13d40fb24</td>\n",
       "      <td>2016-01-14</td>\n",
       "      <td>3.496508</td>\n",
       "      <td>14</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2016</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           air_store_id visit_date  visitors  Day  Dayofweek  Month  Year  \\\n",
       "0  air_ba937bf13d40fb24 2016-01-13  3.258097   13          2      1  2016   \n",
       "1  air_ba937bf13d40fb24 2016-01-14  3.496508   14          3      1  2016   \n",
       "\n",
       "   Day_num  \n",
       "0       12  \n",
       "1       13  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_data.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lag Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_lag_dow(df, lag_list, column):\n",
    "    for lag in lag_list:\n",
    "        column_lag = column + \"_\" + str(lag)\n",
    "        df[column_lag] = df.groupby(['air_store_id','Dayofweek'])[column].shift(lag, fill_value=0)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(284127, 10)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = all_data[['air_store_id','Dayofweek','visitors']].groupby(['air_store_id','Dayofweek']).agg({'visitors':'mean'}).reset_index()\n",
    "df = df.rename(columns={'visitors':'visitors_mean_dow'}) \n",
    "all_data = all_data.merge(df,on=['air_store_id','Dayofweek'], how='left')\n",
    "\n",
    "df = all_data[['air_store_id','Dayofweek','visitors']].groupby(['air_store_id','Dayofweek']).agg({'visitors':'sum'}).reset_index()\n",
    "df = df.rename(columns={'visitors':'visitors_sum_dow'}) \n",
    "all_data = all_data.merge(df,on=['air_store_id','Dayofweek'], how='left')\n",
    "\n",
    "del df\n",
    "all_data.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data = calculate_lag_dow(all_data, [1], 'visitors_mean_dow')\n",
    "all_data = calculate_lag_dow(all_data, [1], 'visitors_sum_dow')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_lag_mon(df, lag_list, column):\n",
    "    for lag in lag_list:\n",
    "        column_lag = column + \"_\" + str(lag)\n",
    "        df[column_lag] = df.groupby(['air_store_id','Month'])[column].shift(lag, fill_value=0)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(284127, 13)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = all_data[all_data['Year']==2016][['air_store_id','Month','visitors']].groupby(['air_store_id','Month']).agg({'visitors':'mean'}).reset_index()\n",
    "df = df.rename(columns={'visitors':'visitors_mean_mon'}) \n",
    "all_data = all_data.merge(df,on=['air_store_id','Month'], how='left')\n",
    "\n",
    "del df\n",
    "all_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data = calculate_lag_mon(all_data, [1], 'visitors_mean_mon')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data.set_index('visit_date',inplace=True)\n",
    "expand_min = all_data.groupby(['air_store_id']).visitors_mean_dow.expanding().min().reset_index()\n",
    "expand_min.rename(columns={'visitors_mean_dow':'expand_min'},inplace=True)\n",
    "\n",
    "all_data.reset_index(inplace=True)\n",
    "all_data = all_data.merge(expand_min, on=['air_store_id','visit_date'], how='left')\n",
    "all_data.shape\n",
    "\n",
    "del expand_min"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data = calculate_lag_dow(all_data, [1], 'expand_min')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data.set_index('visit_date',inplace=True)\n",
    "expand_max = all_data.groupby(['air_store_id']).visitors_mean_dow.expanding().max().reset_index()\n",
    "expand_max.rename(columns={'visitors_mean_dow':'expand_max'},inplace=True)\n",
    "\n",
    "all_data.reset_index(inplace=True)\n",
    "all_data = all_data.merge(expand_max, on=['air_store_id','visit_date'], how='left')\n",
    "all_data.shape\n",
    "\n",
    "del expand_max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data = calculate_lag_dow(all_data, [1], 'expand_max')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data.set_index('visit_date',inplace=True)\n",
    "expand_mean = all_data.groupby(['air_store_id']).visitors_mean_dow.expanding().mean().reset_index()\n",
    "expand_mean.rename(columns={'visitors_mean_dow':'expand_mean'},inplace=True)\n",
    "\n",
    "all_data.reset_index(inplace=True)\n",
    "all_data = all_data.merge(expand_mean, on=['air_store_id','visit_date'], how='left')\n",
    "all_data.shape\n",
    "\n",
    "del expand_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data = calculate_lag_dow(all_data, [1], 'expand_mean')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Air Reserve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>air_store_id</th>\n",
       "      <th>visit_datetime</th>\n",
       "      <th>reserve_datetime</th>\n",
       "      <th>reserve_visitors</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>air_877f79706adbfb06</td>\n",
       "      <td>2016-01-01 19:00:00</td>\n",
       "      <td>2016-01-01 16:00:00</td>\n",
       "      <td>0.693147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>air_db4b38ebe7a7ceff</td>\n",
       "      <td>2016-01-01 19:00:00</td>\n",
       "      <td>2016-01-01 19:00:00</td>\n",
       "      <td>1.386294</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           air_store_id       visit_datetime     reserve_datetime  \\\n",
       "0  air_877f79706adbfb06  2016-01-01 19:00:00  2016-01-01 16:00:00   \n",
       "1  air_db4b38ebe7a7ceff  2016-01-01 19:00:00  2016-01-01 19:00:00   \n",
       "\n",
       "   reserve_visitors  \n",
       "0          0.693147  \n",
       "1          1.386294  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "air_reserve.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>air_store_id</th>\n",
       "      <th>visit_datetime</th>\n",
       "      <th>reserve_datetime</th>\n",
       "      <th>reserve_visitors</th>\n",
       "      <th>visit_date</th>\n",
       "      <th>reserve_date</th>\n",
       "      <th>hour_diff</th>\n",
       "      <th>Day</th>\n",
       "      <th>Dayofweek</th>\n",
       "      <th>Month</th>\n",
       "      <th>Year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>air_877f79706adbfb06</td>\n",
       "      <td>2016-01-01 19:00:00</td>\n",
       "      <td>2016-01-01 16:00:00</td>\n",
       "      <td>0.693147</td>\n",
       "      <td>2016-01-01</td>\n",
       "      <td>2016-01-01</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>2016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>air_db4b38ebe7a7ceff</td>\n",
       "      <td>2016-01-01 19:00:00</td>\n",
       "      <td>2016-01-01 19:00:00</td>\n",
       "      <td>1.386294</td>\n",
       "      <td>2016-01-01</td>\n",
       "      <td>2016-01-01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>2016</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           air_store_id       visit_datetime     reserve_datetime  \\\n",
       "0  air_877f79706adbfb06  2016-01-01 19:00:00  2016-01-01 16:00:00   \n",
       "1  air_db4b38ebe7a7ceff  2016-01-01 19:00:00  2016-01-01 19:00:00   \n",
       "\n",
       "   reserve_visitors visit_date reserve_date  hour_diff  Day  Dayofweek  Month  \\\n",
       "0          0.693147 2016-01-01   2016-01-01        3.0    1          4      1   \n",
       "1          1.386294 2016-01-01   2016-01-01        0.0    1          4      1   \n",
       "\n",
       "   Year  \n",
       "0  2016  \n",
       "1  2016  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#extract information from date\n",
    "air_reserve['visit_date'] = pd.to_datetime(air_reserve['visit_datetime']).dt.date\n",
    "air_reserve['reserve_date'] = pd.to_datetime(air_reserve['reserve_datetime']).dt.date\n",
    "air_reserve['hour_diff']=(pd.to_datetime(air_reserve['visit_datetime'])-pd.to_datetime(air_reserve['reserve_datetime'])).dt.seconds/3600\n",
    "air_reserve['visit_date']=pd.to_datetime(air_reserve['visit_date'])\n",
    "\n",
    "air_reserve = transform(air_reserve)\n",
    "air_reserve.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#aggregate the air reserve df on dates\n",
    "air_final1 = air_reserve[['air_store_id','visit_date','reserve_visitors','hour_diff']].groupby(['air_store_id','visit_date']).agg({'reserve_visitors':'sum','hour_diff':'sum'}).reset_index()\n",
    "#rename the columns\n",
    "air_final1 = air_final1.rename(columns={'reserve_visitors':'air_rv_sum', 'hour_diff':'air_hour_diff_sum'})\n",
    "\n",
    "#aggregate the air reserve df on dates\n",
    "air_final2 = air_reserve[['air_store_id','visit_date','reserve_visitors','hour_diff']].groupby(['air_store_id','visit_date']).agg({'reserve_visitors':'mean','hour_diff':'mean'}).reset_index()\n",
    "#rename the columns\n",
    "air_final2 = air_final2.rename(columns={'reserve_visitors':'air_rv_mean', 'hour_diff':'air_hour_diff_mean'})\n",
    "\n",
    "#merge both sum and mean df\n",
    "air_final = air_final1.merge(air_final2, on = ['air_store_id','visit_date'], how='left')\n",
    "\n",
    "#merge with air reserve\n",
    "all_data = all_data.merge(air_final, on = ['air_store_id','visit_date'], how = 'left')\n",
    "all_data.shape\n",
    "\n",
    "del air_final1, air_final2, air_final"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Air Store Info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>air_store_id</th>\n",
       "      <th>air_genre_name</th>\n",
       "      <th>air_area_name</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>air_0f0cdeee6c9bf3d7</td>\n",
       "      <td>Italian/French</td>\n",
       "      <td>Hyōgo-ken Kōbe-shi Kumoidōri</td>\n",
       "      <td>34.695124</td>\n",
       "      <td>135.197852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>air_7cc17a324ae5c7dc</td>\n",
       "      <td>Italian/French</td>\n",
       "      <td>Hyōgo-ken Kōbe-shi Kumoidōri</td>\n",
       "      <td>34.695124</td>\n",
       "      <td>135.197852</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           air_store_id  air_genre_name                 air_area_name  \\\n",
       "0  air_0f0cdeee6c9bf3d7  Italian/French  Hyōgo-ken Kōbe-shi Kumoidōri   \n",
       "1  air_7cc17a324ae5c7dc  Italian/French  Hyōgo-ken Kōbe-shi Kumoidōri   \n",
       "\n",
       "    latitude   longitude  \n",
       "0  34.695124  135.197852  \n",
       "1  34.695124  135.197852  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "air_store_info.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## latitude and longitude"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>air_store_id</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>air_0f0cdeee6c9bf3d7</td>\n",
       "      <td>34.695124</td>\n",
       "      <td>135.197852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>air_7cc17a324ae5c7dc</td>\n",
       "      <td>34.695124</td>\n",
       "      <td>135.197852</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           air_store_id   latitude   longitude\n",
       "0  air_0f0cdeee6c9bf3d7  34.695124  135.197852\n",
       "1  air_7cc17a324ae5c7dc  34.695124  135.197852"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "air_loc = air_store_info[['air_store_id','latitude','longitude']]\n",
    "air_loc.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\divya\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  if sys.path[0] == '':\n"
     ]
    }
   ],
   "source": [
    "def haversine_array(lat1, lng1, lat2, lng2):\n",
    "    lat1, lng1, lat2, lng2 = map(np.radians, (lat1, lng1, lat2, lng2))\n",
    "    AVG_EARTH_RADIUS = 6371  # in km\n",
    "    lat = lat2 - lat1\n",
    "    lng = lng2 - lng1\n",
    "    d = np.sin(lat * 0.5) ** 2 + np.cos(lat1) * np.cos(lat2) * np.sin(lng * 0.5) ** 2\n",
    "    h = 2 * AVG_EARTH_RADIUS * np.arcsin(np.sqrt(d))\n",
    "    return h\n",
    "\n",
    "lat1 = air_store_info['latitude'].sum()/air_store_info['latitude'].count()\n",
    "lng1 = air_store_info['longitude'].sum()/air_store_info['longitude'].count()\n",
    "air_loc['haversine_dist'] = haversine_array(lat1, lng1, air_loc['latitude'], air_loc['longitude'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "air_loc['longitude_15'] = air_loc['longitude']*np.cos(15* np.pi / 180) - air_loc['latitude']*np.sin(15* np.pi/180)\n",
    "air_loc['longitude_30'] = air_loc['longitude']*np.cos(30* np.pi / 180) - air_loc['latitude']*np.sin(30* np.pi/180)\n",
    "air_loc['longitude_45'] = air_loc['longitude']*np.cos(45* np.pi / 180) - air_loc['latitude']*np.sin(45* np.pi/180)\n",
    "air_loc['longitude_60'] = air_loc['longitude']*np.cos(60* np.pi / 180) - air_loc['latitude']*np.sin(60* np.pi/180)\n",
    "air_loc['longitude_75'] = air_loc['longitude']*np.cos(75* np.pi / 180) - air_loc['latitude']*np.sin(75* np.pi/180)\n",
    "\n",
    "air_loc['latitude_15'] = air_loc['longitude']*np.sin(15* np.pi / 180) + air_loc['latitude']*np.cos(15* np.pi/180)\n",
    "air_loc['latitude_30'] = air_loc['longitude']*np.sin(30* np.pi / 180) + air_loc['latitude']*np.cos(30* np.pi/180)\n",
    "air_loc['latitude_45'] = air_loc['longitude']*np.sin(45* np.pi / 180) + air_loc['latitude']*np.cos(45* np.pi/180)\n",
    "air_loc['latitude_60'] = air_loc['longitude']*np.sin(60* np.pi / 180) + air_loc['latitude']*np.cos(60* np.pi/180)\n",
    "air_loc['latitude_75'] = air_loc['longitude']*np.sin(75* np.pi / 180) + air_loc['latitude']*np.cos(75* np.pi/180)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x26978c7f6a0>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "kmeans = KMeans(n_clusters = 4, init ='k-means++')\n",
    "kmeans.fit(air_loc[air_loc.columns[1:3]]) # Compute k-means clustering.\n",
    "air_loc['cluster_label'] = kmeans.fit_predict(air_loc[air_loc.columns[1:3]])\n",
    "centers = kmeans.cluster_centers_ # Coordinates of cluster centers.\n",
    "labels = kmeans.predict(air_loc[air_loc.columns[1:3]]) # Labels of each point\n",
    "\n",
    "air_loc.plot.scatter(x = 'latitude', y = 'longitude', c=labels, s=50, cmap='viridis')\n",
    "plt.scatter(centers[:, 0], centers[:, 1], c='black', s=200, alpha=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>air_store_id</th>\n",
       "      <th>haversine_dist</th>\n",
       "      <th>longitude_15</th>\n",
       "      <th>longitude_30</th>\n",
       "      <th>longitude_45</th>\n",
       "      <th>longitude_60</th>\n",
       "      <th>longitude_75</th>\n",
       "      <th>latitude_15</th>\n",
       "      <th>latitude_30</th>\n",
       "      <th>latitude_45</th>\n",
       "      <th>latitude_60</th>\n",
       "      <th>latitude_75</th>\n",
       "      <th>cluster_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>air_0f0cdeee6c9bf3d7</td>\n",
       "      <td>227.649705</td>\n",
       "      <td>121.611338</td>\n",
       "      <td>99.737213</td>\n",
       "      <td>71.066161</td>\n",
       "      <td>37.552067</td>\n",
       "      <td>1.478863</td>\n",
       "      <td>68.504696</td>\n",
       "      <td>97.645785</td>\n",
       "      <td>120.132476</td>\n",
       "      <td>134.432337</td>\n",
       "      <td>139.570856</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>air_7cc17a324ae5c7dc</td>\n",
       "      <td>227.649705</td>\n",
       "      <td>121.611338</td>\n",
       "      <td>99.737213</td>\n",
       "      <td>71.066161</td>\n",
       "      <td>37.552067</td>\n",
       "      <td>1.478863</td>\n",
       "      <td>68.504696</td>\n",
       "      <td>97.645785</td>\n",
       "      <td>120.132476</td>\n",
       "      <td>134.432337</td>\n",
       "      <td>139.570856</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>air_fee8dcf4d619598e</td>\n",
       "      <td>227.649705</td>\n",
       "      <td>121.611338</td>\n",
       "      <td>99.737213</td>\n",
       "      <td>71.066161</td>\n",
       "      <td>37.552067</td>\n",
       "      <td>1.478863</td>\n",
       "      <td>68.504696</td>\n",
       "      <td>97.645785</td>\n",
       "      <td>120.132476</td>\n",
       "      <td>134.432337</td>\n",
       "      <td>139.570856</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>air_a17f0778617c76e2</td>\n",
       "      <td>227.649705</td>\n",
       "      <td>121.611338</td>\n",
       "      <td>99.737213</td>\n",
       "      <td>71.066161</td>\n",
       "      <td>37.552067</td>\n",
       "      <td>1.478863</td>\n",
       "      <td>68.504696</td>\n",
       "      <td>97.645785</td>\n",
       "      <td>120.132476</td>\n",
       "      <td>134.432337</td>\n",
       "      <td>139.570856</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>air_83db5aff8f50478e</td>\n",
       "      <td>211.089887</td>\n",
       "      <td>125.760692</td>\n",
       "      <td>103.199401</td>\n",
       "      <td>73.605242</td>\n",
       "      <td>38.995007</td>\n",
       "      <td>1.727327</td>\n",
       "      <td>70.613424</td>\n",
       "      <td>100.756592</td>\n",
       "      <td>124.033365</td>\n",
       "      <td>138.857469</td>\n",
       "      <td>144.218666</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           air_store_id  haversine_dist  longitude_15  longitude_30  \\\n",
       "0  air_0f0cdeee6c9bf3d7      227.649705    121.611338     99.737213   \n",
       "1  air_7cc17a324ae5c7dc      227.649705    121.611338     99.737213   \n",
       "2  air_fee8dcf4d619598e      227.649705    121.611338     99.737213   \n",
       "3  air_a17f0778617c76e2      227.649705    121.611338     99.737213   \n",
       "4  air_83db5aff8f50478e      211.089887    125.760692    103.199401   \n",
       "\n",
       "   longitude_45  longitude_60  longitude_75  latitude_15  latitude_30  \\\n",
       "0     71.066161     37.552067      1.478863    68.504696    97.645785   \n",
       "1     71.066161     37.552067      1.478863    68.504696    97.645785   \n",
       "2     71.066161     37.552067      1.478863    68.504696    97.645785   \n",
       "3     71.066161     37.552067      1.478863    68.504696    97.645785   \n",
       "4     73.605242     38.995007      1.727327    70.613424   100.756592   \n",
       "\n",
       "   latitude_45  latitude_60  latitude_75  cluster_label  \n",
       "0   120.132476   134.432337   139.570856              0  \n",
       "1   120.132476   134.432337   139.570856              0  \n",
       "2   120.132476   134.432337   139.570856              0  \n",
       "3   120.132476   134.432337   139.570856              0  \n",
       "4   124.033365   138.857469   144.218666              1  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "del air_loc['latitude'], air_loc['longitude']\n",
    "air_loc.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(284127, 36)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_data = all_data.merge(air_loc, on = 'air_store_id', how = 'left')\n",
    "all_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "del air_loc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stores per Genre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(284127, 37)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#merge with air genre\n",
    "all_data = all_data.merge(air_store_info[['air_store_id','air_genre_name']].drop_duplicates(), on = ['air_store_id'], how = 'left')\n",
    "all_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "genre_count = air_store_info.groupby('air_genre_name').agg({'air_store_id':'count'}).reset_index()\n",
    "genre_count = genre_count.rename(columns={'air_store_id':'store_count'})\n",
    "\n",
    "all_data = all_data.merge(genre_count, on = ['air_genre_name'], how = 'left')\n",
    "del genre_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(284127, 38)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Checking missing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Total</th>\n",
       "      <th>Percent</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>air_rv_sum</th>\n",
       "      <td>254932</td>\n",
       "      <td>89.724665</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>air_hour_diff_sum</th>\n",
       "      <td>254932</td>\n",
       "      <td>89.724665</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>air_rv_mean</th>\n",
       "      <td>254932</td>\n",
       "      <td>89.724665</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>air_hour_diff_mean</th>\n",
       "      <td>254932</td>\n",
       "      <td>89.724665</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>visitors_mean_mon</th>\n",
       "      <td>68735</td>\n",
       "      <td>24.191647</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>visitors_mean_mon_1</th>\n",
       "      <td>66164</td>\n",
       "      <td>23.286770</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>store_count</th>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>visitors_mean_dow_1</th>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>expand_min</th>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>visitors_sum_dow_1</th>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      Total    Percent\n",
       "air_rv_sum           254932  89.724665\n",
       "air_hour_diff_sum    254932  89.724665\n",
       "air_rv_mean          254932  89.724665\n",
       "air_hour_diff_mean   254932  89.724665\n",
       "visitors_mean_mon     68735  24.191647\n",
       "visitors_mean_mon_1   66164  23.286770\n",
       "store_count               0   0.000000\n",
       "visitors_mean_dow_1       0   0.000000\n",
       "expand_min                0   0.000000\n",
       "visitors_sum_dow_1        0   0.000000"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total = all_data.isnull().sum().sort_values(ascending = False)\n",
    "percent = (all_data.isnull().sum()/all_data.isnull().count()*100).sort_values(ascending = False)\n",
    "missing_train_data  = pd.concat([total, percent], axis=1, keys=['Total', 'Percent'])\n",
    "missing_train_data.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "#all_data = all_data.groupby('air_store_id').apply(lambda group: group.interpolate(limit_direction='both'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data.fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>visit_date</th>\n",
       "      <th>air_store_id</th>\n",
       "      <th>visitors</th>\n",
       "      <th>Day</th>\n",
       "      <th>Dayofweek</th>\n",
       "      <th>Month</th>\n",
       "      <th>Year</th>\n",
       "      <th>Day_num</th>\n",
       "      <th>visitors_mean_dow</th>\n",
       "      <th>visitors_sum_dow</th>\n",
       "      <th>...</th>\n",
       "      <th>longitude_60</th>\n",
       "      <th>longitude_75</th>\n",
       "      <th>latitude_15</th>\n",
       "      <th>latitude_30</th>\n",
       "      <th>latitude_45</th>\n",
       "      <th>latitude_60</th>\n",
       "      <th>latitude_75</th>\n",
       "      <th>cluster_label</th>\n",
       "      <th>air_genre_name</th>\n",
       "      <th>store_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2016-01-13</td>\n",
       "      <td>air_ba937bf13d40fb24</td>\n",
       "      <td>3.258097</td>\n",
       "      <td>13</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2016</td>\n",
       "      <td>12</td>\n",
       "      <td>2.868858</td>\n",
       "      <td>200.820030</td>\n",
       "      <td>...</td>\n",
       "      <td>38.995007</td>\n",
       "      <td>1.727327</td>\n",
       "      <td>70.613424</td>\n",
       "      <td>100.756592</td>\n",
       "      <td>124.033365</td>\n",
       "      <td>138.857469</td>\n",
       "      <td>144.218666</td>\n",
       "      <td>1</td>\n",
       "      <td>Dining bar</td>\n",
       "      <td>108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2016-01-14</td>\n",
       "      <td>air_ba937bf13d40fb24</td>\n",
       "      <td>3.496508</td>\n",
       "      <td>14</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2016</td>\n",
       "      <td>13</td>\n",
       "      <td>2.736528</td>\n",
       "      <td>191.556943</td>\n",
       "      <td>...</td>\n",
       "      <td>38.995007</td>\n",
       "      <td>1.727327</td>\n",
       "      <td>70.613424</td>\n",
       "      <td>100.756592</td>\n",
       "      <td>124.033365</td>\n",
       "      <td>138.857469</td>\n",
       "      <td>144.218666</td>\n",
       "      <td>1</td>\n",
       "      <td>Dining bar</td>\n",
       "      <td>108</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 38 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  visit_date          air_store_id  visitors  Day  Dayofweek  Month  Year  \\\n",
       "0 2016-01-13  air_ba937bf13d40fb24  3.258097   13          2      1  2016   \n",
       "1 2016-01-14  air_ba937bf13d40fb24  3.496508   14          3      1  2016   \n",
       "\n",
       "   Day_num  visitors_mean_dow  visitors_sum_dow  ...  longitude_60  \\\n",
       "0       12           2.868858        200.820030  ...     38.995007   \n",
       "1       13           2.736528        191.556943  ...     38.995007   \n",
       "\n",
       "   longitude_75  latitude_15  latitude_30  latitude_45  latitude_60  \\\n",
       "0      1.727327    70.613424   100.756592   124.033365   138.857469   \n",
       "1      1.727327    70.613424   100.756592   124.033365   138.857469   \n",
       "\n",
       "   latitude_75  cluster_label  air_genre_name  store_count  \n",
       "0   144.218666              1      Dining bar          108  \n",
       "1   144.218666              1      Dining bar          108  \n",
       "\n",
       "[2 rows x 38 columns]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_data.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convert Categorical Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data = pd.get_dummies(all_data, columns=['air_genre_name'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(\"Encoded dataset\")\n",
    "# Label encode air store id. Save dictionary for exploration purposes\n",
    "#all_data['air_store_id'] = le.fit_transform(all_data['air_store_id'])\n",
    "#all_data['station_id'] = le.fit_transform(all_data['station_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "def impact_coding(data, feature, target='y'):\n",
    "    '''\n",
    "    In this implementation we get the values and the dictionary as two different steps.\n",
    "    This is just because initially we were ignoring the dictionary as a result variable.\n",
    "    \n",
    "    In this implementation the KFolds use shuffling. If you want reproducibility the cv \n",
    "    could be moved to a parameter.\n",
    "    '''\n",
    "    n_folds = 5\n",
    "    n_inner_folds = 3\n",
    "    impact_coded = pd.Series()\n",
    "    \n",
    "    oof_default_mean = data[target].mean() # Gobal mean to use by default (you could further tune this)\n",
    "    kf = KFold(n_splits=n_folds, shuffle=True)\n",
    "    oof_mean_cv = pd.DataFrame()\n",
    "    split = 0\n",
    "    for infold, oof in kf.split(data[feature]):\n",
    "            impact_coded_cv = pd.Series()\n",
    "            kf_inner = KFold(n_splits=n_inner_folds, shuffle=True)\n",
    "            inner_split = 0\n",
    "            inner_oof_mean_cv = pd.DataFrame()\n",
    "            oof_default_inner_mean = data.iloc[infold][target].mean()\n",
    "            for infold_inner, oof_inner in kf_inner.split(data.iloc[infold]):\n",
    "                # The mean to apply to the inner oof split (a 1/n_folds % based on the rest)\n",
    "                oof_mean = data.iloc[infold_inner].groupby(by=feature)[target].mean()\n",
    "                impact_coded_cv = impact_coded_cv.append(data.iloc[infold].apply(\n",
    "                            lambda x: oof_mean[x[feature]]\n",
    "                                      if x[feature] in oof_mean.index\n",
    "                                      else oof_default_inner_mean\n",
    "                            , axis=1))\n",
    "\n",
    "                # Also populate mapping (this has all group -> mean for all inner CV folds)\n",
    "                inner_oof_mean_cv = inner_oof_mean_cv.join(pd.DataFrame(oof_mean), rsuffix=inner_split, how='outer')\n",
    "                inner_oof_mean_cv.fillna(value=oof_default_inner_mean, inplace=True)\n",
    "                inner_split += 1\n",
    "\n",
    "            # Also populate mapping\n",
    "            oof_mean_cv = oof_mean_cv.join(pd.DataFrame(inner_oof_mean_cv), rsuffix=split, how='outer')\n",
    "            oof_mean_cv.fillna(value=oof_default_mean, inplace=True)\n",
    "            split += 1\n",
    "            \n",
    "            impact_coded = impact_coded.append(data.iloc[oof].apply(\n",
    "                            lambda x: inner_oof_mean_cv.loc[x[feature]].mean()\n",
    "                                      if x[feature] in inner_oof_mean_cv.index\n",
    "                                      else oof_default_mean\n",
    "                            , axis=1))\n",
    "\n",
    "    return impact_coded, oof_mean_cv.mean(axis=1), oof_default_mean  \n",
    "    \n",
    "    \n",
    "def frequency_encoding(df, col_name):\n",
    "    new_name = \"{}_counts\".format(col_name)\n",
    "    new_col_name = \"{}_freq\".format(col_name)\n",
    "    grouped = df.groupby(col_name).size().reset_index(name=new_name)\n",
    "    df = df.merge(grouped, how = \"left\", on = col_name)\n",
    "    df[new_col_name] = df[new_name]/df[new_name].count()\n",
    "    del df[new_name]\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Impact coding for air_store_id\n",
      "Frequency encoding for air_store_id\n",
      "Wall time: 2min 45s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "categorical_features = [\"air_store_id\"]\n",
    "\n",
    "impact_coding_map = {}\n",
    "for f in categorical_features:\n",
    "        print(\"Impact coding for {}\".format(f))\n",
    "        all_data[\"impact_encoded_{}\".format(f)], impact_coding_mapping, default_coding = impact_coding(all_data, f, target=\"visitors\")\n",
    "        impact_coding_map[f] = (impact_coding_mapping, default_coding)\n",
    "        mapping, default_mean = impact_coding_map[f]\n",
    "        \n",
    "for cat in categorical_features:\n",
    "    print(\"Frequency encoding for {}\".format(f))\n",
    "    all_data = frequency_encoding(all_data, cat)\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = all_data[all_data['Day_num']<478]\n",
    "test = all_data[all_data['Day_num']>=478]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_cols=['visit_date','Day_num','visitors',\n",
    "           'visitors_mean_dow','visitors_sum_dow','visitors_mean_mon',\n",
    "          'air_rv_sum','air_hour_diff_sum','expand_min','expand_max','expand_mean','air_store_id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train[train.Month.isin([1,2,3,4,5,6])].drop(drop_cols, axis=1)\n",
    "Y_train = train[train.Month.isin([1,2,3,4,5,6])]['visitors']\n",
    "\n",
    "\n",
    "X_valid = train[train.Month.isin([7,8,9,10,11,12])].drop(drop_cols, axis=1)\n",
    "Y_valid = train[train.Month.isin([7,8,9,10,11,12])]['visitors']\n",
    "\n",
    "X_test = test.drop(drop_cols, axis=1)\n",
    "#X_test = X_test.drop(['date_block_num'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train shape (125272, 41)\n",
      "Test shape (32019, 41)\n"
     ]
    }
   ],
   "source": [
    "print('Train shape',X_train.shape)\n",
    "print('Test shape',X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression(copy_X=True, fit_intercept=True, n_jobs=None, normalize=False)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "model_lr = LinearRegression()\n",
    "model_lr.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_oof_lr = model_lr.predict(X_train)\n",
    "valid_oof_lr = model_lr.predict(X_valid)\n",
    "pred_lr = model_lr.predict(X_test)\n",
    "sub['visitors']=np.expm1(pred_lr)\n",
    "sub.to_csv('submission_lr.csv',index=False,float_format='%.4f') \n",
    "\n",
    "#with scaler - 2.91385\n",
    "#without scaler - 0.57026"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lasso Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Lasso(alpha=1.0, copy_X=True, fit_intercept=True, max_iter=1000,\n",
       "      normalize=False, positive=False, precompute=False, random_state=42,\n",
       "      selection='cyclic', tol=0.0001, warm_start=False)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import Lasso\n",
    "model_lasso = Lasso(random_state=42)\n",
    "\n",
    "model_lasso.fit(X_train,Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_oof_ls = model_lasso.predict(X_train)\n",
    "valid_oof_ls = model_lasso.predict(X_valid)\n",
    "pred_ls = model_lasso.predict(X_test)\n",
    "sub['visitors']=np.expm1(pred_ls)\n",
    "sub.to_csv('submission_ls.csv',index=False,float_format='%.4f') \n",
    "\n",
    "#with scaler - 2.91385\n",
    "#without scaler - 0.74222"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Light GBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 200 rounds.\n",
      "[1000]\ttraining's l2: 0.248003\ttraining's rmse: 0.497999\tvalid_1's l2: 0.266054\tvalid_1's rmse: 0.515804\n",
      "[2000]\ttraining's l2: 0.238182\ttraining's rmse: 0.488039\tvalid_1's l2: 0.261575\tvalid_1's rmse: 0.511445\n",
      "[3000]\ttraining's l2: 0.232474\ttraining's rmse: 0.482156\tvalid_1's l2: 0.259758\tvalid_1's rmse: 0.509665\n",
      "Early stopping, best iteration is:\n",
      "[3531]\ttraining's l2: 0.230158\ttraining's rmse: 0.479748\tvalid_1's l2: 0.259198\tvalid_1's rmse: 0.509115\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LGBMRegressor(bagging_fraction=0.9, bagging_freq=1, bagging_seed=11,\n",
       "              boosting='gbdt', boosting_type='gbdt', class_weight=None,\n",
       "              colsample_bytree=1.0, feature_fraction=0.9,\n",
       "              importance_type='split', lambda_l1=0.2, learning_rate=0.01,\n",
       "              max_depth=5, metric='l2', min_child_samples=20,\n",
       "              min_child_weight=0.001, min_data_in_leaf=10, min_split_gain=0.0,\n",
       "              n_estimators=20000, n_jobs=-1, nthread=4, num_leaves=10,\n",
       "              objective='regression', random_state=42, reg_alpha=0.0,\n",
       "              reg_lambda=0.0, seed=40, silent=True, subsample=1.0,\n",
       "              subsample_for_bin=200000, subsample_freq=0, ...)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import lightgbm as lgb\n",
    "\n",
    "params = {'num_leaves': 10,\n",
    "         'min_data_in_leaf': 10,\n",
    "         'objective': 'regression',\n",
    "         'max_depth': 5,\n",
    "         'learning_rate': 0.01,\n",
    "         \"boosting\": \"gbdt\",\n",
    "         \"feature_fraction\": 0.9,\n",
    "         \"bagging_freq\": 1,\n",
    "         \"bagging_fraction\": 0.9,\n",
    "         \"bagging_seed\": 11,\n",
    "         \"metric\": 'l2',\n",
    "         \"lambda_l1\": 0.2,\n",
    "         \"verbosity\": -1,\n",
    "         \"random_state\":42\n",
    "         }\n",
    "\n",
    "model_lgb = lgb.LGBMRegressor(**params, n_estimators = 20000, nthread = 4, n_jobs = -1,seed=40)\n",
    "model_lgb.fit(X_train, Y_train, eval_set=[(X_train, Y_train), (X_valid, Y_valid)], eval_metric='rmse',verbose=1000, early_stopping_rounds=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_oof_lgb = model_lgb.predict(X_train, num_iteration=model_lgb.best_iteration_)\n",
    "valid_oof_lgb = model_lgb.predict(X_valid, num_iteration=model_lgb.best_iteration_)\n",
    "pred_lgb = model_lgb.predict(X_test, num_iteration=model_lgb.best_iteration_)\n",
    "sub['visitors']=np.expm1(pred_lgb)\n",
    "sub.to_csv('submission_lgb.csv',index=False,float_format='%.4f') #0.49693"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\tvalidation_0-rmse:2.42799\tvalidation_1-rmse:2.40608\n",
      "Multiple eval metrics have been passed: 'validation_1-rmse' will be used for early stopping.\n",
      "\n",
      "Will train until validation_1-rmse hasn't improved in 10 rounds.\n",
      "Stopping. Best iteration:\n",
      "[571]\tvalidation_0-rmse:0.408805\tvalidation_1-rmse:0.519057\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "XGBRegressor(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "             colsample_bytree=0.8, eta=0.01, gamma=0, learning_rate=0.01,\n",
       "             max_delta_step=0, max_depth=11, min_child_weight=0.5, missing=None,\n",
       "             n_estimators=20000, n_jobs=1, nthread=None, objective='reg:linear',\n",
       "             random_state=42, reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
       "             seed=40, silent=True, subsample=1)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from xgboost.sklearn import XGBClassifier, XGBRegressor\n",
    "\n",
    "xgb_params = {'max_depth' : 11,            \n",
    "              'min_child_weight' : 0.5, \n",
    "            'colsample_bytree' : 0.8, \n",
    "            'subsample':1, \n",
    "            'learning_rate':0.01,\n",
    "            'eta':0.01,    \n",
    "            'seed':40,\n",
    "            'random_state':42\n",
    "             }\n",
    "\n",
    "model_xgb = XGBRegressor(**xgb_params, n_estimators = 20000)\n",
    "model_xgb.fit(X_train, Y_train, eval_set=[(X_train, Y_train), (X_valid, Y_valid)], \n",
    "              eval_metric='rmse',verbose=1000, early_stopping_rounds=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_oof_xgb = model_xgb.predict(X_train)\n",
    "valid_oof_xgb = model_xgb.predict(X_valid)\n",
    "pred_xgb = model_xgb.predict(X_test)\n",
    "sub['visitors']=np.expm1(pred_xgb)\n",
    "sub.to_csv('submission_xgb.csv',index=False,float_format='%.4f') #0.48279"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stacking LGB and XGB using LGB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_stack1 = np.vstack([train_oof_lgb, train_oof_xgb]).transpose()\n",
    "train_stack1 = pd.DataFrame(train_stack1, columns=['lgb', 'xgb'])\n",
    "valid_stack1 = np.vstack([valid_oof_lgb, valid_oof_xgb]).transpose()\n",
    "valid_stack1 = pd.DataFrame(valid_stack1, columns=['lgb', 'xgb'])\n",
    "test_stack1 = np.vstack([pred_lgb, pred_xgb]).transpose()\n",
    "test_stack1 = pd.DataFrame(test_stack1, columns=['lgb', 'xgb'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 200 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[226]\ttraining's l2: 0.175669\ttraining's rmse: 0.419129\tvalid_1's l2: 0.270538\tvalid_1's rmse: 0.520133\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LGBMRegressor(bagging_seed=11, boosting='gbdt', boosting_type='gbdt',\n",
       "              class_weight=None, colsample_bytree=1.0, importance_type='split',\n",
       "              lambda_l1=0.2, learning_rate=0.01, max_depth=2, metric='l2',\n",
       "              min_child_samples=20, min_child_weight=0.001, min_data_in_leaf=20,\n",
       "              min_split_gain=0.0, n_estimators=20000, n_jobs=-1, nthread=4,\n",
       "              num_leaves=8, objective='regression', random_state=42,\n",
       "              reg_alpha=0.0, reg_lambda=0.0, seed=40, silent=True,\n",
       "              subsample=1.0, subsample_for_bin=200000, subsample_freq=0,\n",
       "              verbosity=-1)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import lightgbm as lgb\n",
    "\n",
    "params = {'num_leaves': 8,\n",
    "         'min_data_in_leaf': 20,\n",
    "         'objective': 'regression',\n",
    "         'max_depth': 2,\n",
    "         'learning_rate': 0.01,\n",
    "         \"boosting\": \"gbdt\",\n",
    "         \"bagging_seed\": 11,\n",
    "         \"metric\": 'l2',\n",
    "         \"lambda_l1\": 0.2,\n",
    "         \"verbosity\": -1,\n",
    "         \"random_state\":42,\n",
    "          \"seed\":40\n",
    "         }\n",
    "\n",
    "model_lgb_stack1 = lgb.LGBMRegressor(**params, n_estimators = 20000, nthread = 4, n_jobs = -1)\n",
    "model_lgb_stack1.fit(train_stack1, Y_train, eval_set=[(train_stack1, Y_train), (valid_stack1, Y_valid)], \n",
    "                 eval_metric='rmse',verbose=1000, early_stopping_rounds=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_lgb_stack1 = model_lgb_stack1.predict(test_stack1, num_iteration=model_lgb_stack1.best_iteration_) \n",
    "sub['visitors']=np.expm1(pred_lgb_stack1) \n",
    "sub.to_csv('submission_lgb_stack1.csv',index=False,float_format='%.4f') #0.49180"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stacking LGB and XGB using XGB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\tvalidation_0-rmse:2.21343\tvalidation_1-rmse:2.19932\n",
      "Multiple eval metrics have been passed: 'validation_1-rmse' will be used for early stopping.\n",
      "\n",
      "Will train until validation_1-rmse hasn't improved in 10 rounds.\n",
      "Stopping. Best iteration:\n",
      "[49]\tvalidation_0-rmse:0.421327\tvalidation_1-rmse:0.517315\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "XGBRegressor(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "             colsample_bytree=0.8, eta=0.01, gamma=0, learning_rate=0.1,\n",
       "             max_delta_step=0, max_depth=5, min_child_weight=0.5, missing=None,\n",
       "             n_estimators=20000, n_jobs=1, nthread=None, objective='reg:linear',\n",
       "             random=40, random_state=0, reg_alpha=0, reg_lambda=1,\n",
       "             scale_pos_weight=1, seed=42, silent=True, subsample=1)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from xgboost.sklearn import XGBClassifier, XGBRegressor\n",
    "\n",
    "xgb_params = {'max_depth' : 5,            \n",
    "              'min_child_weight' : 0.5, \n",
    "            'colsample_bytree' : 0.8, \n",
    "            'subsample':1, \n",
    "            'eta':0.01,    \n",
    "            'seed':42,\n",
    "             'random':40\n",
    "             }\n",
    "\n",
    "model_xgb_stack1 = XGBRegressor(**xgb_params, n_estimators = 20000)\n",
    "model_xgb_stack1.fit(train_stack1, Y_train, eval_set=[(train_stack1, Y_train), (valid_stack1, Y_valid)], eval_metric='rmse',verbose=1000, early_stopping_rounds=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_xgb_stack1 = model_xgb_stack1.predict(test_stack1)\n",
    "sub['visitors']=np.expm1(pred_xgb_stack1)\n",
    "sub.to_csv('submission_xgb_stack1.csv',index=False,float_format='%.4f') #0.48745"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Blending with LGB and XGB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub['visitors'] = np.expm1((pred_lgb + pred_xgb) / 2)\n",
    "sub.to_csv(\"blend_lgb_xgb.csv\", index=False) #0.48800"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub['visitors'] = np.expm1((pred_lgb_stack1 + pred_xgb_stack1) / 2)\n",
    "sub.to_csv(\"blend_lgb_xgb_stack.csv\", index=False) #0.48395"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub['visitors'] = np.expm1((0.4*pred_lgb + 0.6*pred_xgb))\n",
    "sub.to_csv(\"blend_lgb_xgb_wt.csv\", index=False) #0.48704"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gradient Boost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GradientBoostingRegressor(alpha=0.9, criterion='friedman_mse', init=None,\n",
       "                          learning_rate=0.1, loss='ls', max_depth=3,\n",
       "                          max_features=None, max_leaf_nodes=None,\n",
       "                          min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                          min_samples_leaf=1, min_samples_split=2,\n",
       "                          min_weight_fraction_leaf=0.0, n_estimators=100,\n",
       "                          n_iter_no_change=None, presort='auto',\n",
       "                          random_state=None, subsample=1.0, tol=0.0001,\n",
       "                          validation_fraction=0.1, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "\n",
    "params = {'max_depth': 5,\n",
    "         'n_estimators':2000,\n",
    "          'learning_rate':0.1,\n",
    "          'subsample':0.8,\n",
    "         \"random_state\":42,\n",
    "          \"seed\":40\n",
    "         }\n",
    "model_gbr = GradientBoostingRegressor()\n",
    "\n",
    "model_gbr.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_oof_gbr = model_gbr.predict(X_train)\n",
    "valid_oof_gbr = model_gbr.predict(X_valid)\n",
    "pred_gbr = model_gbr.predict(X_test)\n",
    "sub['visitors']=np.expm1(pred_gbr)\n",
    "sub.to_csv('submission_gbr.csv',index=False,float_format='%.4f') #0.51489"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stacking LGB, XGB, GBR using LGB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_stack2 = np.vstack([train_oof_lgb, train_oof_xgb, train_oof_gbr]).transpose()\n",
    "train_stack2 = pd.DataFrame(train_stack2, columns=['lgb', 'xgb', 'gbr'])\n",
    "valid_stack2 = np.vstack([valid_oof_lgb, valid_oof_xgb, valid_oof_gbr]).transpose()\n",
    "valid_stack2 = pd.DataFrame(valid_stack2, columns=['lgb', 'xgb', 'gbr'])\n",
    "test_stack2 = np.vstack([pred_lgb, pred_xgb, pred_gbr]).transpose()\n",
    "test_stack2 = pd.DataFrame(test_stack2, columns=['lgb', 'xgb', 'gbr'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 200 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[226]\ttraining's l2: 0.175669\ttraining's rmse: 0.419129\tvalid_1's l2: 0.270538\tvalid_1's rmse: 0.520133\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LGBMRegressor(bagging_seed=11, boosting='gbdt', boosting_type='gbdt',\n",
       "              class_weight=None, colsample_bytree=1.0, importance_type='split',\n",
       "              lambda_l1=0.2, learning_rate=0.01, max_depth=2, metric='l2',\n",
       "              min_child_samples=20, min_child_weight=0.001, min_data_in_leaf=20,\n",
       "              min_split_gain=0.0, n_estimators=20000, n_jobs=-1, nthread=4,\n",
       "              num_leaves=8, objective='regression', random_state=42,\n",
       "              reg_alpha=0.0, reg_lambda=0.0, seed=40, silent=True,\n",
       "              subsample=1.0, subsample_for_bin=200000, subsample_freq=0,\n",
       "              verbosity=-1)"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import lightgbm as lgb\n",
    "\n",
    "params = {'num_leaves': 8,\n",
    "         'min_data_in_leaf': 20,\n",
    "         'objective': 'regression',\n",
    "         'max_depth': 2,\n",
    "         'learning_rate': 0.01,\n",
    "         \"boosting\": \"gbdt\",\n",
    "         \"bagging_seed\": 11,\n",
    "         \"metric\": 'l2',\n",
    "         \"lambda_l1\": 0.2,\n",
    "         \"verbosity\": -1,\n",
    "         \"random_state\":42,\n",
    "          \"seed\":40\n",
    "         }\n",
    "\n",
    "model_lgb_stack2 = lgb.LGBMRegressor(**params, n_estimators = 20000, nthread = 4, n_jobs = -1)\n",
    "model_lgb_stack2.fit(train_stack2, Y_train, eval_set=[(train_stack2, Y_train), (valid_stack2, Y_valid)], \n",
    "                 eval_metric='rmse',verbose=1000, early_stopping_rounds=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_lgb_stack2 = model_lgb_stack2.predict(test_stack2, num_iteration=model_lgb_stack2.best_iteration_)\n",
    "sub['visitors']=np.expm1(pred_lgb_stack2)\n",
    "sub.to_csv('submission_lgb_stack2.csv',index=False,float_format='%.4f') #0.49180"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stacking LGB, XGB, GBR using XGB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\tvalidation_0-rmse:2.21294\tvalidation_1-rmse:2.20117\n",
      "Multiple eval metrics have been passed: 'validation_1-rmse' will be used for early stopping.\n",
      "\n",
      "Will train until validation_1-rmse hasn't improved in 10 rounds.\n",
      "Stopping. Best iteration:\n",
      "[34]\tvalidation_0-rmse:0.387099\tvalidation_1-rmse:0.541049\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "XGBRegressor(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "             colsample_bytree=0.8, eta=0.01, gamma=0, learning_rate=0.1,\n",
       "             max_delta_step=0, max_depth=5, min_child_weight=0.5, missing=None,\n",
       "             n_estimators=20000, n_jobs=1, nthread=None, objective='reg:linear',\n",
       "             random=40, random_state=0, reg_alpha=0, reg_lambda=1,\n",
       "             scale_pos_weight=1, seed=42, silent=True, subsample=1)"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from xgboost.sklearn import XGBClassifier, XGBRegressor\n",
    "\n",
    "xgb_params = {'max_depth' : 5,            \n",
    "              'min_child_weight' : 0.5, \n",
    "            'colsample_bytree' : 0.8, \n",
    "            'subsample':1, \n",
    "            'eta':0.01,    \n",
    "            'seed':42,\n",
    "             'random':40\n",
    "             }\n",
    "\n",
    "model_xgb_stack2 = XGBRegressor(**xgb_params, n_estimators = 20000)\n",
    "model_xgb_stack2.fit(train_stack2, Y_train, eval_set=[(train_stack2, Y_train), (valid_stack2, Y_valid)], \n",
    "                     eval_metric='rmse',verbose=1000, early_stopping_rounds=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_xgb_stack2 = model_xgb_stack2.predict(test_stack2)\n",
    "sub['visitors']=np.expm1(pred_xgb_stack2)\n",
    "sub.to_csv('submission_xgb_stack2.csv',index=False,float_format='%.4f') #0.49765"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KNeighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsRegressor(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "                    metric_params=None, n_jobs=-1, n_neighbors=15, p=2,\n",
       "                    weights='uniform')"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "model_knn = KNeighborsRegressor(n_jobs=-1, n_neighbors=15)\n",
    "model_knn.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_oof_knn = model_knn.predict(X_train)\n",
    "valid_oof_knn = model_knn.predict(X_valid)\n",
    "pred_knn = model_knn.predict(X_test)\n",
    "sub['visitors']=np.expm1(pred_knn)\n",
    "sub.to_csv('submission_knn.csv',index=False,float_format='%.4f') #0.52786"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Blending with LGB, XGB, Gradient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub['visitors'] = np.expm1((pred_lgb + pred_xgb + pred_gbr) / 3)\n",
    "sub.to_csv(\"blend_lgb_xgb_gbr.csv\", index=False) #0.49387"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Blending with LGB, XGB, Gradient and KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub['visitors'] = np.expm1((pred_lgb + pred_xgb + pred_gbr + pred_knn) / 4)\n",
    "sub.to_csv(\"blend_lgb_xgb_gbr_knn.csv\", index=False) #0.49447"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Blending with LGB, XGB, Gradient and KNN with weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub['visitors'] = np.expm1((0.2*pred_lgb + 0.6*pred_xgb + 0.1*pred_gbr +0.1*pred_knn))\n",
    "sub.to_csv(\"blend_lgb_xgb_gbr_wt.csv\", index=False) #0.48737"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gmean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "#concatenate target columns on the same Dataframe\n",
    "sub = pd.read_csv(\"C:/Users/divya/Downloads/recruit-restaurant-visitor-forecasting/sample_submission/sample_submission.csv\")\n",
    "sub1 = sub.copy()\n",
    "sub1['visitors']=np.expm1(pred_lgb)\n",
    "\n",
    "sub2 = sub.copy()\n",
    "sub2['visitors']=np.expm1(pred_xgb)\n",
    "\n",
    "#sub3 = sub.copy()\n",
    "#sub3['visitors']=np.expm1(pred_gbr)\n",
    "\n",
    "#sub4 = sub.copy()\n",
    "#sub4['visitors']=np.expm1(pred_knn)\n",
    "\n",
    "preds = pd.concat([sub1['visitors'], sub2['visitors']])#,  sub3['visitors'], sub4['visitors']])\n",
    "\n",
    "from scipy.stats.mstats import gmean\n",
    "\n",
    "#Apply geometric mean \n",
    "preds = preds.groupby(level=0).apply(gmean)\n",
    "\n",
    "sub['visitors'] = preds\n",
    "sub.to_csv(\"blend_gmean.csv\", index=False) #0.48801"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "#concatenate target columns on the same Dataframe\n",
    "sub = pd.read_csv(\"C:/Users/divya/Downloads/recruit-restaurant-visitor-forecasting/sample_submission/sample_submission.csv\")\n",
    "sub1 = sub.copy()\n",
    "sub1['visitors']=np.expm1(pred_lgb_stack1)\n",
    "\n",
    "sub2 = sub.copy()\n",
    "sub2['visitors']=np.expm1(pred_xgb_stack1)\n",
    "\n",
    "#sub3 = sub.copy()\n",
    "#sub3['visitors']=np.expm1(pred_gbr)\n",
    "\n",
    "#sub4 = sub.copy()\n",
    "#sub4['visitors']=np.expm1(pred_knn)\n",
    "\n",
    "preds = pd.concat([sub1['visitors'], sub2['visitors']])#,  sub3['visitors'], sub4['visitors']])\n",
    "\n",
    "from scipy.stats.mstats import gmean\n",
    "\n",
    "#Apply geometric mean \n",
    "preds = preds.groupby(level=0).apply(gmean)\n",
    "\n",
    "sub['visitors'] = preds\n",
    "sub.to_csv(\"blend_gmean_stack.csv\", index=False) #0.48801"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
